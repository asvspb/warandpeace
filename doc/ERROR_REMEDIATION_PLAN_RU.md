# План устранения ошибок (Gemini, Telegram, устойчивость)

Дата: 2025-08-15
Ответственный: команда бота «Война и мир»

## Ремарка (15.08.2025)

План реализован частично. По итогам аудита кода и логов бот стабилен за счёт фолбэка на Mistral, но остаются 5 критичных хвостов, которые желательно закрыть перед следующими крупными задачами:
- Исправить обработку 429 (ResourceExhausted): порядок `except`, учитывать `retry_delay` → выставлять `cooldown_until` и продолжать перебор ключей в текущем вызове.
- Заменить `hash(api_key)` на стабильный `sha256(api_key).hexdigest()` для корректной работы кэша статусов.
- При `geo_unsupported` не завершать запрос, а сразу пробовать следующий ключ.
- Понизить уровни логов для ожидаемых ошибок Gemini (400/429) до WARNING и агрегировать сообщения за запуск.
- Добавить ретраи `tenacity` для `send_message`/`get_chat` и TTL‑кэш результата `get_chat`.

Готовы двигаться дальше, но рекомендую сначала закрыть эти пункты (оценка: 0.5–1 рабочий день), чтобы снизить шум и задержки.

## 1) Диагностика по логам (факты)

- Gemini API:
  - 429 Quota exceeded (free tier, model: `gemini-2.0-flash-exp`), присутствует `retry_delay` (11–35 сек).
  - 400 User location is not supported — повторяется для ключей #2/#3.
  - Фолбэк на Mistral срабатывает, публикации продолжаются, но тратится время на неуспешные попытки Gemini и зашумляются логи.
- Telegram API (python-telegram-bot + httpx/httpcore):
  - Периодические `httpx.ReadError`/`httpx.ConnectError` в polling (`get_updates`) и при `get_chat`. Ошибки ловятся глобальным обработчиком; задача продолжает работу; публикации успешны.
- Прочее:
  - Контейнер на Python 3.10. Планируется миграция на 3.11 (см. `PY311_MIGRATION_PLAN.md`).
  - Логи хранятся в stdout контейнера; отдельной ротации/файлов нет.

## 2) Цели

- Снизить долю ошибок Gemini в логах и задержки на неуспешные попытки.
- Обеспечить предсказуемый фолбэк-путь (вплоть до отключения Gemini при устойчивых проблемах региона/квоты).
- Минимизировать «красные» ошибки Telegram за счёт корректных ретраев и таймаутов; исключить влияние на публикации.
- Улучшить наблюдаемость: метрики по LLM-провайдерам, классификация причин фолбэка, алерты по порогам.

## 3) План работ (этапы)

### Этап 1 — Быстрая стабилизация фолбэка Gemini (сегодня)
- [X] **Кэширование статуса ключей**: при 400 `User location is not supported` помечать ключ как `geo_unsupported` и исключать из перебора на 24 часа (in-memory + файл `temp/gemini_key_status.json`).
  - Статусы и файл реализованы в `src/summarizer.py` (`_load_key_status/_save_key_status`, `geo_unsupported`).
- [ ] **Исправить баг с 429 (quota)**: сейчас обработчик `ResourceExhausted` недостижим из-за размещения после `except Exception`. Нужно:
  - [ ] Перестроить блок `try/except` так, чтобы `except ResourceExhausted` шёл раньше общего `except Exception` и действительно срабатывал.
  - [ ] Заполнять `cooldown_until` с учётом `retry_delay` из ответа (если доступно), минимум 1–5 минут.
  - [ ] После пометки ключа — продолжать перебор следующего ключа в рамках того же вызова (не `return None` преждевременно).
- [ ] **Стабильный идентификатор ключа**: вместо `hash(api_key)` использовать `sha256(api_key).hexdigest()` для стабильности между процессами/перезапусками.
- [ ] **Не прерывать перебор при geo_unsupported**: помечать ключ и сразу пробовать следующий в текущем вызове (не выходить `return None`), чтобы не тратить попытку на каждом артикле.
- [X] **Выбор стабильной модели**: модель выносится в `ENV` (`GEMINI_MODEL`), дефолт `gemini-2.0-flash` — реализовано в `src/config.py`.
- [ ] **Политика provider order**: если активных ключей Gemini нет (или доля успехов < порога), на 6 часов делать Mistral первичным (`LLM_PRIMARY=mistral` в рантайме либо авто‑переключатель).
- [ ] **Логирование**: понизить ожидаемые ошибки Gemini (400/429) до WARNING и агрегировать: одно сообщение на запуск, без повторов на каждую статью.
- [X] **Метрики**: счётчики `llm_requests_total` и `llm_fallbacks_total` — уже есть в `src/metrics.py` и используются в `src/summarizer.py`.

Критерии приёмки:
- За один запуск при массовых 400/429 в логах максимум 1 агрегированное WARNING-сообщение вместо N ошибок.
- Время публикации 1–3 статей ≈ время работы Mistral (без заметной задержки на попытки Gemini).

### Этап 2 — Телеграм: сетевые ошибки и таймауты (завтра)
- [X] **Таймауты**: заданы через `HTTPXRequest` в `src/bot.py` (`TG_*_TIMEOUT`) — реализовано.
- [ ] **Ретраи с backoff**: обернуть `send_message` и `get_chat` в ретраи `tenacity` (2–3 попытки, экспонента 1–4–8 сек) с логикой отмены при `BadRequest`.
- [ ] **Кэш канала**: кэшировать `username`/`title` на 6–24 ч.; при сбое публиковать по `TELEGRAM_CHANNEL_ID` (fallback уже есть) — добавить TTL‑кэш, чтобы не дергать `get_chat` каждый цикл.
- [ ] **Логирование**: в глобальном обработчике понижать до WARNING для `NetworkError/TimedOut`, если восстановление произошло менее чем за 60 секунд; убирать длинные стектрейсы из INFO‑потока.

Критерии приёмки:
- Нет красных ERROR по Telegram в обычной работе; при кратковременных сбоях — 1–2 WARNING и авто-восстановление.
- Публикации не прерываются.

### Этап 3 — Наблюдаемость и алерты (послезавтра)
- [ ] **Гистограммы**: `llm_latency_seconds{provider,model}`, `telegram_send_seconds` (в `src/metrics.py`).
- [ ] **Пороговые алерты/автопереключение**: если `llm_fallbacks_total` за 1 час > 10 или success‑rate Gemini < 20% — одно админ‑уведомление (с троттлингом) и авто‑переключение приоритета провайдеров на 6 часов.
- [ ] **Dashboard**: графики по провайдерам, латентность, публикации.

Критерии приёмки:
- Видны графики; алерт срабатывает при ручной симуляции отказа Gemini и не спамит.

### Этап 4 — Рефакторинг обёрток провайдеров (на этой неделе)
- [ ] **Интерфейс LLMProvider**: единый протокол и классы адаптеров; единая типизация ошибок (`QuotaExceeded`, `GeoUnsupported`, `NetworkIssue`).
- [ ] **Circuit breaker**: на провайдера и на ключ — запрет на окно при устойчивых ошибках.
- [ ] **Конфиг через ENV**: `GEMINI_ENABLED`, `MISTRAL_ENABLED`, `LLM_PRIMARY`, `GEMINI_MODEL`, `MISTRAL_MODEL`, `LLM_MAX_TOKENS`, `LLM_TIMEOUT_SEC`.
- [ ] **Тесты**: мок httpx для 400/429/5xx; юнит‑тесты failover/cooldown; интеграционный тест фолбэка.

Критерии приёмки:
- Все тесты зелёные; ручной прогон демонстрирует устойчивый фолбэк без задержек.

### Этап 5 — Логи и хранение (опционально)
- [ ] **Файловая ротация**: `TimedRotatingFileHandler` (сутки, хранить 7) в `/app/logs/bot.log`; добавить том `./logs:/app/logs` в docker-compose.
- [ ] **JSON-логи**: флаг `LOG_JSON=true` для структурных логов (не по умолчанию).

Критерии приёмки:
- Логи доступны на хосте, размер ограничен, формат читаемый.

### Этап 6 — Миграция на Python 3.11 (после стабилизации)
- [ ] Выполнить шаги из `PY311_MIGRATION_PLAN.md` (базовый образ, зависимости, тесты, смоук).

## 4) Изменения в конфигурации (.env)

- Новые/уточнённые переменные:
  - `GEMINI_ENABLED=true|false`
  - `MISTRAL_ENABLED=true|false`
  - `LLM_PRIMARY=gemini|mistral`
  - `GEMINI_MODEL=gemini-2.0-flash`
  - `MISTRAL_MODEL=open-mistral-nemo|mistral-large-latest` (по доступности)
  - `LLM_TIMEOUT_SEC=30`
  - `LLM_MAX_TOKENS=512`

## 5) Точки правок в коде

- `src/summarizer.py`:
  - [ ] Вынести провайдеры в классы; добавить кеш статусов ключей, circuit breaker, чтение retry_delay, агрегацию логов.
  - [ ] Переехать на модель из ENV и порядок провайдеров.
  - [ ] Метрики и причины фолбэка.
- `src/bot.py`:
  - [ ] Минимизировать вызовы `get_chat` (кэш, TTL) и обернуть Telegram-вызовы ретраями `tenacity`.
  - [ ] Настроить PTB `Request` с таймаутами/лимитами.
- `src/notifications.py`:
  - [ ] Троттлинг алертов по провайдерам (не более 1 уведомления/час на причину).
- `docker-compose.yml` (опционально):
  - [ ] Добавить том `./logs:/app/logs` при включении файловых логов.

## 6) Риски и откаты

- Смена дефолтной модели Gemini может изменить стиль резюме — проверка визуально в канале; быстрый откат через ENV.
- Жёсткое отключение Gemini при массовых ошибках — рост нагрузки/стоимости на Mistral; мониторить бюджет.
- Дополнительные ретраи Telegram — удлинение «хвостов» при реальных авариях сети; настроить верхние границы времени.

## 7) Коммуникации и релиз

- Ветка: `hotfix/llm-fallback-stabilization` → PR → деплой.
- До релиза: тесты, локальный прогон задач суммаризации на выборке (3–5 статей), проверка логов/метрик.
- После релиза: мониторинг 24–48 часов; приёмка по критериям каждого этапа.
